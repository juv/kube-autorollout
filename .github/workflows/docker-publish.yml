name: Docker Build

on:
  schedule:
    - cron: '31 9 * * *'
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  release:
    types: [ published ]

env:
  REGISTRY: ghcr.io
  # github.repository as <account>/<repo>
  IMAGE_NAME: ${{ github.repository }}


jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      # This is used to complete the identity challenge
      # with sigstore/fulcio when running outside of PRs.
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install cosign
        if: github.event_name != 'pull_request'
        uses: sigstore/cosign-installer@59acb6260d9c0ba8f4a2f9d9b48431a222b68e20 # v3.5.0
        with:
          cosign-release: 'v2.2.4'

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@f95db51fddba0c2d1ec667646a06c2ce06100226 # v3.0.0

      - name: Log into registry ${{ env.REGISTRY }}
        if: github.event_name != 'pull_request'
        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract Docker metadata
        id: meta
        uses: docker/metadata-action@96383f45573cb7f253c731d3b3ab81c87ef81934 # v5.0.0
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=sha,format=long
          type=ref,event=pr

      - name: Build and push Docker image
        id: build-and-push
        uses: docker/build-push-action@0565240e2d4ab88bba5387d719585280857ece09 # v5.0.0
        with:
          context: .
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # Sign the resulting Docker image digest except on PRs.
      # This will only write to the public Rekor transparency log when the Docker
      # repository is public to avoid leaking data.  If you would like to publish
      # transparency data even for private images, pass --force to cosign below.
      # https://github.com/sigstore/cosign
      - name: Sign the published Docker image
        if: ${{ github.event_name != 'pull_request' }}
        env:
          TAGS: ${{ steps.meta.outputs.tags }}
          DIGEST: ${{ steps.build-and-push.outputs.digest }}
        # This step uses the identity token to provision an ephemeral certificate
        # against the sigstore community Fulcio instance.
        run: echo "${TAGS}" | xargs -I {} cosign sign --yes {}@${DIGEST}
    outputs:
      tags: ${{ steps.meta.outputs.tags }}
  update-release:
    needs: build
    if: github.event_name == 'release' && github.event.action == 'published'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Update GitHub release notes with built Docker image info
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const tag = context.ref.replace('refs/tags/', '');
            const release = await github.rest.repos.getReleaseByTag({
              owner: owner,
              repo: repo,
              tag: tag
            });
            // Fail if release body is empty or undefined
            if (!release.data.body || release.data.body.trim() === '') {
              throw new Error(`Release notes for tag ${tag} is empty. Aborting update of release notes.`);
            }
            let body = release.data.body;
            
            const versionsResponse = await github.rest.packages.getAllPackageVersionsForPackageOwnedByUser({
              package_type: 'container',
              package_name: repo,
              username: owner,
            });
  
            // Find the version matching the release tag
            const matchingVersion = versionsResponse.data.find(version =>
              version.metadata?.container?.tags?.includes(tag)
            );
            
            if (!matchingVersion) {
              throw new Error(`No package version found with tag ${tag}`);
            }
            
            const versionId = matchingVersion.id;
            const packageUrl = `https://github.com/${owner}/${repo}/pkgs/container/${repo}/${versionId}?tag=${tag}`;
            const ghcrImageName = `ghcr.io/${owner}/${repo}:${tag}`;
            const imageInfo = `\n\n## Images\nDocker Image: \`${ghcrImageName}\`\nGitHub Packages: [ghcr.io/${owner}/${repo}](${packageUrl})`;
            
            if (!body.includes(imageInfo)) {
              body += imageInfo;
              await github.rest.repos.updateRelease({
                owner: owner,
                repo: repo,
                release_id: release.data.id,
                body: body
              });
            }
  # End-to-End testing with multiple Kubernetes versions
  e2e-test:
    runs-on: ubuntu-latest
    needs: build
    strategy:
      fail-fast: false
      matrix:
        k8s-version:
          - v1.32
          - v1.33
          - v1.34

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up k3d cluster
        uses: nolar/setup-k3d-k3s@v1
        with:
          version: ${{ matrix.k8s-version }}
          k3d-name: kube-autorollout-e2e
          k3d-args: >-
            --no-lb
            --no-rollback
            --k3s-arg --disable=traefik,servicelb,metrics-server@server:*

      - name: Verify cluster is ready
        run: |
          kubectl cluster-info
          kubectl get nodes
          kubectl wait --for=condition=ready nodes --all --timeout=60s

      - name: Install kube-autorollout using Helm
        run: |
          # Import kube-autorollout image to k3d cluster
          for tag in ${{ steps.meta.outputs.tags }}; do
            k3d image import "$tag" --cluster kube-autorollout-e2e || true
          done
          
          # Install kube-autorollout from Helm Chart 
          helm install kube-autorollout ./charts/kube-autorollout --wait --timeout=30s --set image.tag=${{ github.sha }}
          
          # Wait for kube-autorollout controller to be ready
          kubectl get pods -l app.kubernetes.io/name=kube-autorollout          
          kubectl wait --for=condition=available deployment/kube-autorollout --timeout=30s
          kubectl logs deployment/kube-autorollout --tail=50
          
      - name: Create GHCR image pull secret in k3d cluster
        run: |
          kubectl create secret docker-registry ghcr-pull-secret \
            --docker-server=ghcr.io \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GITHUB_TOKEN }}

      - name: Build and push initial test application image
        id: build-test-image
        run: |
          # Create a simple test application
          mkdir -p test-app
          cat > test-app/Dockerfile << 'EOF'
          FROM nginx:alpine-slim
          COPY index.html /usr/share/nginx/html/
          EXPOSE 80
          CMD ["nginx", "-g", "daemon off;"]
          EOF
          
          cat > test-app/index.html << 'EOF'
          <html><body><h1>Test App v1</h1></body></html>
          EOF
          
          # Build and push initial version
          E2E_TAG=e2e-test-app-k8s-${{ matrix.k8s-version }}
          docker build -t ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$E2E_TAG test-app/
          docker push ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$E2E_TAG
          
          # Get initial digest
          INITIAL_DIGEST=$(docker inspect --format='{{index .RepoDigests 0}}' ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$E2E_TAG | cut -d'@' -f2)
          echo "INITIAL_DIGEST=$INITIAL_DIGEST" >> $GITHUB_ENV
          echo "E2E_TAG=$E2E_TAG" >> $GITHUB_ENV

      - name: Create test deployment
        run: |
          REGISTRY=${{ env.REGISTRY }}
          IMAGE_NAME=${{ env.IMAGE_NAME }}
          E2E_TAG=${{ steps.build-test-image.outputs.E2E_TAG }}
          # Create a test deployment that kube-autorollout should monitor
          kubectl apply -f - <<EOF
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: test-app
            annotations:
              kube-autorollout.io/enabled: "true"
          spec:
            replicas: 2
            selector:
              matchLabels:
                app: test-app
            template:
              metadata:
                labels:
                  app: test-app
              spec:
                imagePullSecrets:
                - name: ghcr-pull-secret
                containers:
                - name: test-app
                  image: $REGISTRY/$IMAGE_NAME:$E2E_TAG
                  ports:
                  - containerPort: 80
          EOF

      - name: Wait for test deployment to be ready
        id: wait-for-test-app
        run: |
          kubectl wait --for=condition=available deployment/test-app --timeout=60s
          
          kubectl get deployment test-app -o wide
          
          # Get initial generation
          INITIAL_GENERATION=$(kubectl get deployment test-app -o jsonpath='{.metadata.generation}')
          echo "Initial deployment generation: $INITIAL_GENERATION"
          
          echo "INITIAL_GENERATION=$INITIAL_GENERATION" >> $GITHUB_ENV

      - name: Build and push changed test application image
        run: |
          # Change output of index.html to trigger a "change" in the image
          cat > test-app/index.html << 'EOF'
          <html><body><h1>Test App v2</h1></body></html>
          EOF
          
          # Build and push initial version
          E2E_TAG=${{ steps.build-test-image.outputs.E2E_TAG }}
          docker build -t ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$E2E_TAG test-app/
          docker push ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$E2E_TAG
          
          # Get initial digest
          UPDATED_DIGEST=$(docker inspect --format='{{index .RepoDigests 0}}' ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$E2E_TAG | cut -d'@' -f2)
          
          # Verify digests are different
          if [ "$INITIAL_DIGEST" = "$NEW_DIGEST" ]; then
          echo "ERROR: Digests should be different but are the same!"
          exit 1
          fi        
        
          echo "UPDATED_DIGEST=$UPDATED_DIGEST" >> $GITHUB_ENV

      - name: Confirm kube-autorollout works :-)
        run: |
          INITIAL_GENERATION=${{ steps.wait-for-test-app.outputs.INITIAL_GENERATION }}
          
          # Wait for generation to change (indicating a rollout was triggered)
          for i in {1..60}; do
            CURRENT_GENERATION=$(kubectl get deployment test-app -o jsonpath='{.metadata.generation}')
            echo "Current generation: $CURRENT_GENERATION (attempt $i/60)"
            
            if [ "$CURRENT_GENERATION" -gt "$INITIAL_GENERATION" ]; then
              echo "✅ Rollout detected! Generation changed from $INITIAL_GENERATION to $CURRENT_GENERATION"
              break
            fi
            
            if [ $i -eq 60 ]; then
              echo "❌ Timeout waiting for rollout to be triggered"
              kubectl logs -l app.kubernetes.io/name=kube-autorollout --tail=100
              exit 1
            fi
            
            sleep 5
          done
          
          echo "UPDATED_DIGEST=$UPDATED_DIGEST" >> $GITHUB_ENV